{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103d2edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 1: SETUP & DATA GENERATION ---\n",
    "import numpy as np\n",
    "import hnswlib\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "# Global Configuration\n",
    "DIM = 128               # Vector dimensionality\n",
    "NUM_ELEMENTS = 50000    # Database size\n",
    "NUM_QUERIES = 100       # Number of queries to test\n",
    "TARGET_K = 1            # Target K for deep dive analysis (Recall@1)\n",
    "K_VALUES = [1, 5, 10, 20, 50, 100] # K values for general benchmarking\n",
    "\n",
    "# Normalization Function (Required for Cosine Distance)\n",
    "def normalize(v):\n",
    "    return v / np.linalg.norm(v, axis=1, keepdims=True)\n",
    "\n",
    "print(f\"üîÑ Generating {NUM_ELEMENTS} random vectors...\")\n",
    "\n",
    "# Generate random float32 data\n",
    "raw_data = np.random.random((NUM_ELEMENTS, DIM)).astype(np.float32)\n",
    "raw_queries = np.random.random((NUM_QUERIES, DIM)).astype(np.float32)\n",
    "\n",
    "# Normalize data for Cosine space\n",
    "data = normalize(raw_data)\n",
    "queries = normalize(raw_queries)\n",
    "\n",
    "print(\"‚úÖ Data generation and normalization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c06eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 2: CORE FUNCTIONS ---\n",
    "\n",
    "def run_brute_force_cosine(dataset, query_vectors, k):\n",
    "    \"\"\"\n",
    "    Executes exact Brute Force search using matrix multiplication.\n",
    "    Optimized for Cosine distance (1 - Dot Product).\n",
    "    Returns: (indices, time_taken_seconds)\n",
    "    \"\"\"\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    # Calculate Cosine Distance: 1 - Dot Product (assuming normalized vectors)\n",
    "    # shape: (num_queries, num_elements)\n",
    "    dists = 1 - np.dot(query_vectors, dataset.T)\n",
    "    \n",
    "    # Get top k indices with smallest distance\n",
    "    indices = np.argsort(dists, axis=1)[:, :k]\n",
    "    \n",
    "    end = time.perf_counter()\n",
    "    return indices, end - start\n",
    "\n",
    "def calculate_recall(ground_truth, predicted):\n",
    "    \"\"\"\n",
    "    Calculates average Recall@K.\n",
    "    Recall = (Intersection of Relevant and Retrieved) / (Total Relevant)\n",
    "    \"\"\"\n",
    "    total_recall = 0\n",
    "    k = ground_truth.shape[1]\n",
    "    num_queries = len(ground_truth)\n",
    "    \n",
    "    for i in range(num_queries):\n",
    "        # Use python sets for fast intersection\n",
    "        gt_set = set(ground_truth[i])\n",
    "        pred_set = set(predicted[i])\n",
    "        \n",
    "        match_count = len(gt_set.intersection(pred_set))\n",
    "        total_recall += match_count / k\n",
    "        \n",
    "    return total_recall / num_queries\n",
    "\n",
    "# Pre-calculate Ground Truth for K=1 (Baseline for further tests)\n",
    "print(\"‚è≥ Running Brute Force to establish Ground Truth (K=1)...\")\n",
    "gt_indices_k1, bf_time_k1 = run_brute_force_cosine(data, queries, k=1)\n",
    "bf_time_us = (bf_time_k1 / NUM_QUERIES) * 1_000_000 # Convert to microseconds\n",
    "print(f\"‚úÖ Ground Truth ready. Brute Force Avg Time: {bf_time_us:.2f} ¬µs/query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c8a541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 3: PART 1 - GENERAL BENCHMARK (Time & Recall vs K) ---\n",
    "\n",
    "# 1. Get Ground Truth for max K\n",
    "max_k = max(K_VALUES)\n",
    "print(f\"‚è≥ Calculating Ground Truth for K={max_k}...\")\n",
    "gt_indices_max, bf_time_total = run_brute_force_cosine(data, queries, k=max_k)\n",
    "bf_time_avg_us = (bf_time_total / NUM_QUERIES) * 1_000_000\n",
    "print(f\"üëâ Brute Force (Baseline): {bf_time_avg_us:.2f} ¬µs\")\n",
    "\n",
    "# 2. Build HNSW Index (Standard Configuration)\n",
    "print(\"\\nüèóÔ∏è Building HNSW Index (M=16, efConst=200)...\")\n",
    "p = hnswlib.Index(space='cosine', dim=DIM)\n",
    "p.init_index(max_elements=NUM_ELEMENTS, ef_construction=200, M=16)\n",
    "p.add_items(data)\n",
    "p.set_ef(100) # High accuracy query-time setting\n",
    "print(\"‚úÖ Index built.\")\n",
    "\n",
    "# 3. Run Benchmark Loop\n",
    "results_k = {'k': [], 'hnsw_time': [], 'recall': []}\n",
    "\n",
    "print(f\"\\nüöÄ Benchmark Results:\")\n",
    "print(f\"{'K':<5} | {'HNSW Time (¬µs)':<15} | {'Recall':<10}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for k in K_VALUES:\n",
    "    # Measure HNSW time\n",
    "    start = time.perf_counter()\n",
    "    hnsw_labels, _ = p.knn_query(queries, k=k)\n",
    "    end = time.perf_counter()\n",
    "    \n",
    "    avg_time_us = ((end - start) / NUM_QUERIES) * 1_000_000\n",
    "    \n",
    "    # Calculate Recall\n",
    "    # Slice the ground truth to match current k\n",
    "    current_gt = gt_indices_max[:, :k]\n",
    "    recall = calculate_recall(current_gt, hnsw_labels)\n",
    "    \n",
    "    # Store results\n",
    "    results_k['k'].append(k)\n",
    "    results_k['hnsw_time'].append(avg_time_us)\n",
    "    results_k['recall'].append(recall)\n",
    "    \n",
    "    print(f\"{k:<5} | {avg_time_us:<15.2f} | {recall:.4f}\")\n",
    "\n",
    "# --- PLOTTING ---\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Time Comparison (Log Scale)\n",
    "ax1.plot(results_k['k'], results_k['hnsw_time'], 'g-s', label='HNSW Index', linewidth=2)\n",
    "ax1.axhline(y=bf_time_avg_us, color='r', linestyle='--', label='Brute Force', linewidth=2)\n",
    "ax1.set_title('Average Query Time Comparison')\n",
    "ax1.set_xlabel('K (Number of Neighbors)')\n",
    "ax1.set_ylabel('Time (¬µs) - Log Scale')\n",
    "ax1.set_yscale('log') \n",
    "ax1.grid(True, which=\"both\", ls=\"-\", alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Plot 2: Recall Accuracy\n",
    "ax2.plot(results_k['k'], results_k['recall'], 'b-D', label='HNSW Recall', linewidth=2)\n",
    "ax2.set_title('Recall@K Accuracy')\n",
    "ax2.set_xlabel('K (Number of Neighbors)')\n",
    "ax2.set_ylabel('Recall Score (0.0 - 1.0)')\n",
    "ax2.set_ylim(0, 1.05)\n",
    "ax2.grid(True, alpha=0.5)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5ee8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 4: PART 2 - PARAMETER TUNING EXPERIMENT ---\n",
    "# Objective: Analyze how M and efConstruction affect Speed and Accuracy.\n",
    "\n",
    "# Experiment Configuration\n",
    "M_values = [4, 8, 16, 32, 64]           # Max links per node\n",
    "efConst_values = [16, 64, 200]          # Index construction quality\n",
    "efSearch_values = [10, 20, 40, 80, 120, 160, 200, 300] # Search depth\n",
    "\n",
    "# Storage: results[efConst][M] = { 'recall': [], 'time': [] }\n",
    "experiment_results = {}\n",
    "\n",
    "print(\"üöÄ Starting Deep Dive Experiment (This may take a few minutes)...\")\n",
    "total_steps = len(efConst_values) * len(M_values)\n",
    "step_count = 0\n",
    "\n",
    "for efConst in efConst_values:\n",
    "    experiment_results[efConst] = {}\n",
    "    print(f\"\\n--- Testing efConstruction = {efConst} ---\")\n",
    "    \n",
    "    for M in M_values:\n",
    "        step_count += 1\n",
    "        print(f\"  [{step_count}/{total_steps}] Building Index M={M}...\", end=\" \")\n",
    "        \n",
    "        try:\n",
    "            # 1. Build Index\n",
    "            p = hnswlib.Index(space='cosine', dim=DIM)\n",
    "            p.init_index(max_elements=NUM_ELEMENTS, ef_construction=efConst, M=M)\n",
    "            p.add_items(data)\n",
    "            \n",
    "            recalls = []\n",
    "            times = []\n",
    "            \n",
    "            # 2. Test different efSearch values\n",
    "            for ef in efSearch_values:\n",
    "                p.set_ef(ef)\n",
    "                \n",
    "                start_t = time.perf_counter()\n",
    "                labels, _ = p.knn_query(queries, k=1) # Query K=1\n",
    "                end_t = time.perf_counter()\n",
    "                \n",
    "                # Store metrics\n",
    "                times.append(((end_t - start_t) / NUM_QUERIES) * 1_000_000)\n",
    "                recalls.append(calculate_recall(gt_indices_k1, labels))\n",
    "                \n",
    "            experiment_results[efConst][M] = {'recall': recalls, 'time': times}\n",
    "            print(f\"Done. Max Recall: {max(recalls):.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Deep Dive Experiment Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5491a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 5: VISUALIZATION - RECALL@1 vs efSearch ---\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharey=True)\n",
    "colors = ['purple', 'cyan', 'green', 'orange', 'blue', 'red']\n",
    "color_map = dict(zip(M_values, colors))\n",
    "\n",
    "for i, efConst in enumerate(efConst_values):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    if efConst in experiment_results:\n",
    "        for M in M_values:\n",
    "            if M in experiment_results[efConst]:\n",
    "                y_values = experiment_results[efConst][M]['recall']\n",
    "                ax.plot(efSearch_values, y_values, marker='.', linewidth=2,\n",
    "                        color=color_map.get(M, 'gray'), label=f'M={M}')\n",
    "\n",
    "    # Styling\n",
    "    ax.set_title(f'efConstruction = {efConst}', fontsize=12, fontweight='bold', color='#333')\n",
    "    ax.set_xlabel('efSearch (Query Effort)')\n",
    "    ax.set_ylim(0, 1.05)\n",
    "    ax.grid(True, linestyle='--', alpha=0.5)\n",
    "    \n",
    "    if i == 0: ax.set_ylabel('Recall@1 Score')\n",
    "    if i == 2: ax.legend(title='M (Links)', loc='lower right')\n",
    "\n",
    "plt.suptitle(\"Impact of Parameters on Accuracy (Recall@1)\", fontsize=14, y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f34b618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 6: VISUALIZATION - SEARCH TIME vs efSearch ---\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharey=True)\n",
    "\n",
    "# Auto-scale Y-axis to fit both HNSW and Brute Force\n",
    "all_times = []\n",
    "for ef in experiment_results:\n",
    "    for m in experiment_results[ef]:\n",
    "        all_times.extend(experiment_results[ef][m]['time'])\n",
    "        \n",
    "y_min = min(all_times) * 0.8 if all_times else 10\n",
    "y_max = max(max(all_times), bf_time_us) * 1.5 # Ensure Brute Force is visible\n",
    "\n",
    "for i, efConst in enumerate(efConst_values):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # 1. Plot HNSW Curves\n",
    "    if efConst in experiment_results:\n",
    "        for M in M_values:\n",
    "            if M in experiment_results[efConst]:\n",
    "                y_values = experiment_results[efConst][M]['time']\n",
    "                ax.plot(efSearch_values, y_values, marker='.', linewidth=2,\n",
    "                        color=color_map.get(M, 'gray'), label=f'M={M}')\n",
    "\n",
    "    # 2. Plot Brute Force Baseline\n",
    "    ax.axhline(y=bf_time_us, color='red', linestyle='--', linewidth=2, label='Brute Force')\n",
    "\n",
    "    # Styling\n",
    "    ax.set_title(f'efConstruction = {efConst}', fontsize=12, fontweight='bold', color='#333')\n",
    "    ax.set_xlabel('efSearch')\n",
    "    ax.set_yscale('log') # Log scale for better visibility\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.grid(True, linestyle='--', alpha=0.5)\n",
    "    \n",
    "    if i == 0: ax.set_ylabel('Search Time (¬µs) - Log Scale')\n",
    "    if i == 2: \n",
    "        # Get handles to organize legend\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend(handles, labels, title='Parameters', loc='center right', bbox_to_anchor=(1.4, 0.5))\n",
    "\n",
    "plt.suptitle(\"Impact of Parameters on Search Speed (HNSW vs Brute Force)\", fontsize=14, y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b7adb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 7: GRAPH STRUCTURE ANALYSIS (Simulation) ---\n",
    "# NOTE: Since hnswlib doesn't expose internal graph data easily in Python,\n",
    "# we simulate the theoretical structure for visualization purposes.\n",
    "\n",
    "def simulate_hnsw_structure(num_elements, M):\n",
    "    layers = []\n",
    "    # Layer 0 (Bottom Layer): Contains all nodes\n",
    "    # Degree distribution is Gaussian around 2*M\n",
    "    deg_L0 = np.random.normal(loc=M*2, scale=M/2, size=num_elements).astype(int)\n",
    "    deg_L0 = np.clip(deg_L0, 1, None) # Ensure at least 1 link\n",
    "    layers.append(deg_L0)\n",
    "    \n",
    "    # Upper Layers: Number of nodes decays exponentially (1/M)\n",
    "    count = num_elements\n",
    "    while count > M:\n",
    "        count = int(count / M)\n",
    "        if count == 0: break\n",
    "        # Upper layers typically have degree around M\n",
    "        deg = np.random.normal(loc=M, scale=M/4, size=count).astype(int)\n",
    "        layers.append(deg)\n",
    "    return layers\n",
    "\n",
    "# Generate mock data for M=16\n",
    "mock_layers = simulate_hnsw_structure(NUM_ELEMENTS, 16)\n",
    "node_counts = [len(l) for l in mock_layers]\n",
    "\n",
    "# Plotting\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Plot 1: Hierarchy (Nodes per Layer)\n",
    "ax1.bar(range(len(node_counts)), node_counts, color='teal', alpha=0.7, edgecolor='black')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_title('HNSW Hierarchy (Nodes per Layer)')\n",
    "ax1.set_xlabel('Layer Level (0 = Bottom)')\n",
    "ax1.set_ylabel('Node Count (Log Scale)')\n",
    "for i, v in enumerate(node_counts):\n",
    "    ax1.text(i, v, str(v), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Plot 2: Connectivity (Degree Distribution at Layer 0)\n",
    "ax2.hist(mock_layers[0], bins=50, color='purple', alpha=0.6, edgecolor='black')\n",
    "ax2.axvline(np.mean(mock_layers[0]), color='orange', linestyle='--', linewidth=2, label='Avg Degree')\n",
    "ax2.set_title('Connectivity (Degree Distribution @ Layer 0)')\n",
    "ax2.set_xlabel('Number of Links (Degree)')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.legend()\n",
    "\n",
    "plt.suptitle(\"Structural Analysis of HNSW Graph (Simulated)\", fontsize=14, y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WEB-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
