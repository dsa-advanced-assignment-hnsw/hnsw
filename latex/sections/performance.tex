\chapter{Đánh giá hiệu suất}

\section{Phương pháp đánh giá}

\subsection{Cấu hình phần cứng và môi trường}
Các thí nghiệm được thực hiện trên môi trường sau:
\begin{itemize}
    \item \textbf{CPU}: Intel Core i7 hoặc tương đương
    \item \textbf{RAM}: 16GB trở lên
    \item \textbf{GPU}: NVIDIA GPU (tùy chọn, cho việc mã hóa embedding)
    \item \textbf{Python}: 3.10+
    \item \textbf{Thư viện}: hnswlib 0.8.0, numpy 1.24.0, PyTorch 2.0+
\end{itemize}

Hoặc có thể chạy trên Google Colab với GPU miễn phí để tăng tốc quá trình mã hóa.

\subsection{Cấu hình thí nghiệm}
Thí nghiệm chính được thực hiện trên tập dữ liệu benchmark với các tham số:
\begin{itemize}
    \item \textbf{Số lượng vector}: 50,000
    \item \textbf{Số chiều}: 128 (cho thí nghiệm benchmark)
    \item \textbf{Số truy vấn}: 100
    \item \textbf{Giá trị K}: [1, 5, 10, 20, 50, 100]
    \item \textbf{Cấu hình HNSW}: M=40, efConstruction=200, ef=100
\end{itemize}

Các thí nghiệm trên dữ liệu production sử dụng:
\begin{itemize}
    \item \textbf{Hình ảnh}: 100,000 vector, 512 chiều
    \item \textbf{Tài liệu}: 100,000 vector, 1024 chiều
    \item \textbf{Y tế}: 3,400 vector, 512 chiều
\end{itemize}

\section{Các chỉ số đánh giá}

\subsection{Độ trễ (Latency)}
Độ trễ được đo bằng thời gian trung bình để thực hiện một truy vấn, tính bằng micro giây (µs). Kết quả từ thí nghiệm benchmark được trình bày trong \Cref{tab:latency_comparison}.

\begin{table}[htbp]
    \centering
    \caption{So sánh độ trễ giữa HNSW và Brute-force}
    \label{tab:latency_comparison}
    \begin{tabular}{@{}cccc@{}}
        \toprule
        \textbf{K} & \textbf{HNSW (µs)} & \textbf{Brute-force (µs)} & \textbf{Tốc độ nhanh hơn} \\
        \midrule
        1 & 42.95 & 1,432.21 & 33.3x \\
        5 & 50.11 & 1,354.02 & 27.0x \\
        10 & 49.77 & 1,357.78 & 27.3x \\
        20 & 52.05 & 1,381.91 & 26.6x \\
        50 & 73.72 & 1,434.37 & 19.5x \\
        100 & 55.70 & 1,390.85 & 25.0x \\
        \bottomrule
    \end{tabular}
\end{table}

Kết quả cho thấy HNSW nhanh hơn brute-force từ 19.5 đến 33.3 lần, với độ trễ trung bình dưới 60 micro giây cho tất cả các giá trị K. Điều này chứng tỏ HNSW rất hiệu quả cho các ứng dụng yêu cầu độ trễ thấp.

\subsection{Độ chính xác (Accuracy)}
Độ chính xác được đo bằng Recall@K, được định nghĩa là tỷ lệ các kết quả từ HNSW xuất hiện trong top-K kết quả chính xác từ brute-force. Kết quả được trình bày trong \Cref{tab:recall_comparison}.

\begin{table}[htbp]
    \centering
    \caption{Độ chính xác Recall@K của HNSW}
    \label{tab:recall_comparison}
    \begin{tabular}{@{}cc@{}}
        \toprule
        \textbf{K} & \textbf{Recall@K} \\
        \midrule
        1 & 0.8900 \\
        5 & 0.8400 \\
        10 & 0.8330 \\
        20 & 0.8050 \\
        50 & 0.7724 \\
        100 & 0.7263 \\
        \bottomrule
    \end{tabular}
\end{table}

Kết quả cho thấy HNSW đạt độ chính xác cao, với Recall@1 = 0.89 và Recall@10 = 0.83. Điều này có nghĩa là 89\% các kết quả top-1 và 83\% các kết quả top-10 từ HNSW trùng khớp với kết quả chính xác từ brute-force.

\subsection{Khả năng mở rộng (Scalability)}
Khả năng mở rộng được đánh giá bằng cách đo thời gian xây dựng chỉ mục và thời gian truy vấn khi tăng số lượng vector. Kết quả được trình bày trong \Cref{fig:scalability}.

Độ phức tạp thời gian:
\begin{itemize}
    \item \textbf{Xây dựng chỉ mục}: $O(N \log N)$ - Tăng gần như tuyến tính với log factor
    \item \textbf{Truy vấn}: $O(\log N)$ - Tăng rất chậm khi tăng số lượng vector
    \item \textbf{Bộ nhớ}: $O(N \times M)$ - Tuyến tính với số lượng vector và số kết nối
\end{itemize}

Với cấu hình M=200, hệ thống có thể xử lý:
\begin{itemize}
    \item 100,000 vector: ~3-4GB RAM, thời gian xây dựng ~5-10 phút
    \item 1,000,000 vector: ~30-40GB RAM, thời gian xây dựng ~1-2 giờ
    \item 10,000,000 vector: ~300-400GB RAM, thời gian xây dựng ~10-20 giờ
\end{itemize}

\section{Thống kê đồ thị}

\subsection{Số lượng tầng}
Đồ thị HNSW được xây dựng với nhiều tầng, trong đó:
\begin{itemize}
    \item \textbf{Tầng 0}: Chứa tất cả các vector, mật độ kết nối cao nhất
    \item \textbf{Các tầng cao hơn}: Mật độ giảm dần, mỗi tầng chứa khoảng $1/M$ số vector so với tầng dưới
    \item \textbf{Số tầng trung bình}: $\log_M(N)$ với $N$ là số lượng vector
\end{itemize}

Với N=50,000 và M=40, số tầng trung bình là khoảng 3-4 tầng.

\subsection{Bậc trung bình của nút}
Mỗi nút trong đồ thị HNSW có tối đa $M$ kết nối ở mỗi tầng (trừ tầng 0 có thể có $2M$). Bậc trung bình của nút:
\begin{itemize}
    \item \textbf{Tầng 0}: ~200 kết nối (M=200)
    \item \textbf{Các tầng cao hơn}: ~200 kết nối (M=200)
    \item \textbf{Tổng số cạnh}: ~$N \times M$ cạnh
\end{itemize}

\subsection{Phân phối điểm vào}
Điểm vào (entry point) là nút ở tầng cao nhất, được chọn ngẫu nhiên trong quá trình xây dựng. Phân phối điểm vào:
\begin{itemize}
    \item \textbf{Số lượng điểm vào}: Thường là 1, đôi khi 2-3 nếu có nhiều nút ở tầng cao nhất
    \item \textbf{Vị trí}: Được lưu trữ riêng để truy cập nhanh khi khởi động
\end{itemize}

\section{Điều chỉnh tham số}

\subsection{Ảnh hưởng của tham số M}
Tham số M (số kết nối tối đa) ảnh hưởng đến:
\begin{itemize}
    \item \textbf{Độ chính xác}: M lớn hơn → độ chính xác cao hơn nhưng chậm hơn
    \item \textbf{Bộ nhớ}: M lớn hơn → sử dụng nhiều bộ nhớ hơn
    \item \textbf{Thời gian xây dựng}: M lớn hơn → mất nhiều thời gian hơn
\end{itemize}

Kết quả thí nghiệm với các giá trị M khác nhau:
\begin{itemize}
    \item M=4: Recall@1 ≈ 0.65, thời gian truy vấn ~20µs
    \item M=16: Recall@1 ≈ 0.80, thời gian truy vấn ~35µs
    \item M=32: Recall@1 ≈ 0.85, thời gian truy vấn ~45µs
    \item M=64: Recall@1 ≈ 0.88, thời gian truy vấn ~55µs
    \item M=200: Recall@1 ≈ 0.89, thời gian truy vấn ~60µs
\end{itemize}

\subsection{Ảnh hưởng của efConstruction}
Tham số efConstruction (số láng giềng xem xét khi xây dựng) ảnh hưởng đến:
\begin{itemize}
    \item \textbf{Chất lượng đồ thị}: efConstruction lớn hơn → đồ thị tốt hơn
    \item \textbf{Thời gian xây dựng}: efConstruction lớn hơn → mất nhiều thời gian hơn
\end{itemize}

Kết quả thí nghiệm:
\begin{itemize}
    \item efConstruction=16: Thời gian xây dựng nhanh, nhưng Recall@1 ≈ 0.75
    \item efConstruction=64: Cân bằng tốt, Recall@1 ≈ 0.85
    \item efConstruction=200: Chất lượng tốt, Recall@1 ≈ 0.89 (được chọn)
    \item efConstruction=400: Chất lượng rất tốt, Recall@1 ≈ 0.90, nhưng chậm hơn đáng kể
\end{itemize}

\subsection{Ảnh hưởng của efSearch}
Tham số efSearch (số láng giềng xem xét khi tìm kiếm) ảnh hưởng đến:
\begin{itemize}
    \item \textbf{Độ chính xác}: efSearch lớn hơn → độ chính xác cao hơn
    \item \textbf{Thời gian truy vấn}: efSearch lớn hơn → chậm hơn
\end{itemize}

Kết quả thí nghiệm với efSearch khác nhau:
\begin{itemize}
    \item efSearch=10: Thời gian ~25µs, Recall@1 ≈ 0.70
    \item efSearch=40: Thời gian ~40µs, Recall@1 ≈ 0.85
    \item efSearch=100: Thời gian ~50µs, Recall@1 ≈ 0.89 (được chọn)
    \item efSearch=200: Thời gian ~60µs, Recall@1 ≈ 0.90
    \item efSearch=300: Thời gian ~80µs, Recall@1 ≈ 0.91
\end{itemize}

\section{So sánh với các phương pháp khác}

\subsection{So sánh với LSH}
Locality Sensitive Hashing (LSH) là một phương pháp ANN khác dựa trên hash tables. So sánh:
\begin{itemize}
    \item \textbf{Độ chính xác}: HNSW thường đạt Recall cao hơn LSH
    \item \textbf{Tốc độ}: HNSW nhanh hơn LSH trong hầu hết các trường hợp
    \item \textbf{Bộ nhớ}: LSH có thể tiết kiệm bộ nhớ hơn một chút
    \item \textbf{Độ phức tạp}: Cả hai đều có độ phức tạp $O(\log N)$ cho truy vấn
\end{itemize}

\subsection{So sánh với VP-Tree}
Vantage Point Tree là phương pháp ANN dựa trên cây. So sánh:
\begin{itemize}
    \item \textbf{Độ chính xác}: HNSW đạt độ chính xác cao hơn
    \item \textbf{Tốc độ}: HNSW nhanh hơn đáng kể
    \item \textbf{Bộ nhớ}: VP-Tree tiết kiệm bộ nhớ hơn
    \item \textbf{Khả năng mở rộng}: HNSW mở rộng tốt hơn cho dữ liệu lớn
\end{itemize}

