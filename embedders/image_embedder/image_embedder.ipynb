{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAGE EMBEDDER\n",
    "This notebook implements a complete pipeline to **download a batch of images from a URL list**, use the **OpenAI CLIP (ViT-B/32) model** to **convert them into vector embeddings**, and finally **merge all vectors** into a single HDF5 file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initialization and Setup\n",
    "Installs all necessary Python libraries, including **torch**, **h5py**, **gdown** *(for Google Drive downloads)*, **Pillow** *(for image processing)*, **ipywidgets** *(for tqdm)*, and most importantly, **clip** *(installed directly from OpenAI's GitHub)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-sevti835\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-sevti835\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (2.32.5)\n",
      "Requirement already satisfied: boto3 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (1.40.69)\n",
      "Requirement already satisfied: h5py in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (3.15.1)\n",
      "Requirement already satisfied: gdown in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (5.2.0)\n",
      "Requirement already satisfied: torch in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (2.9.0)\n",
      "Requirement already satisfied: tqdm in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: typing in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: Pillow in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (12.0.0)\n",
      "Requirement already satisfied: ipywidgets in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (8.1.8)\n",
      "Requirement already satisfied: ftfy in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from clip==1.0) (6.3.1)\n",
      "Requirement already satisfied: packaging in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from clip==1.0) (25.0)\n",
      "Requirement already satisfied: regex in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from clip==1.0) (2025.11.3)\n",
      "Requirement already satisfied: torchvision in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from clip==1.0) (0.24.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from requests) (2025.11.12)\n",
      "Requirement already satisfied: botocore<1.41.0,>=1.40.69 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from boto3) (1.40.69)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from boto3) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from botocore<1.41.0,>=1.40.69->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.69->boto3) (1.17.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from gdown) (4.14.2)\n",
      "Requirement already satisfied: filelock in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from gdown) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from ipywidgets) (9.7.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from ipywidgets) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from ipywidgets) (3.0.16)\n",
      "Requirement already satisfied: decorator>=4.3.2 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from jedi>=0.18.1->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from beautifulsoup4->gdown) (2.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from requests[socks]->gdown) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests boto3 h5py gdown torch tqdm typing numpy gdown Pillow ipywidgets git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import h5py\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import subprocess\n",
    "import clip\n",
    "import gdown\n",
    "from PIL import Image\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data and Tool Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloads the `downloader.py` utility script, part of the **Open Images dataset** toolkit. This script is used for efficient, parallel downloading of the dataset images and is stored in the `.cache` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T11:42:38.409642Z",
     "iopub.status.busy": "2025-11-02T11:42:38.409065Z",
     "iopub.status.idle": "2025-11-02T11:44:05.777123Z",
     "shell.execute_reply": "2025-11-02T11:44:05.776371Z",
     "shell.execute_reply.started": "2025-11-02T11:42:38.409599Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Ensure the local cache directory exists.\n",
    "os.makedirs(\".cache\", exist_ok=True)\n",
    "\n",
    "# Check if the downloader script already exists in the cache.\n",
    "if not os.path.isfile(\".cache/downloader.py\"):\n",
    "    # If not present, download the script from the remote repository.\n",
    "    command = [\"wget\", \"-O\", \".cache/downloader.py\", \"https://raw.githubusercontent.com/openimages/dataset/master/downloader.py\"]\n",
    "    # Execute the download command and ensure it runs successfully.\n",
    "    subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloads metadata files (`image_ids.json`, `image_urls.json`) derived from the **Open Images V7 dataset**, hosted on a Google Drive mirror. This data is used in accordance with the original **CC BY 4.0 License**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the main directory for raw dataset storage.\n",
    "# 'exist_ok=True' prevents errors if the folder is already present.\n",
    "os.makedirs(\"RAW_DATASET\", exist_ok=True)\n",
    "\n",
    "# Check if the 'image_ids' file exists. If not, download it from Google Drive.\n",
    "if not os.path.isfile(\"RAW_DATASET/image_ids.json\"):\n",
    "    # Download file using its Google Drive ID.\n",
    "    gdown.download(id='1-HcMviWpMn84cDaDkDpPXqEr-6BFc0bv', output='RAW_DATASET/image_ids.json', quiet=False)\n",
    "\n",
    "# Check if the 'image_urls' file exists. If not, download it from Google Drive.\n",
    "if not os.path.isfile(\"RAW_DATASET/image_urls.json\"):\n",
    "    # Download file using its Google Drive ID.\n",
    "    gdown.download(id='16F8VRuKZb4SJ0KLa1Oh281RvdmQzj6Ft', output='RAW_DATASET/image_urls.json', quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Loading and Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T11:45:04.134917Z",
     "iopub.status.busy": "2025-11-02T11:45:04.134291Z",
     "iopub.status.idle": "2025-11-02T11:45:04.138852Z",
     "shell.execute_reply": "2025-11-02T11:45:04.138086Z",
     "shell.execute_reply.started": "2025-11-02T11:45:04.134890Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def read_json(file_path):\n",
    "    # Open the JSON file for reading, ensuring UTF-8 support.\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        # Load and return the data as a Python list.\n",
    "        data = json.load(f)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image identifiers from the local JSON file.\n",
    "image_IDs = read_json(\"RAW_DATASET/image_ids.json\")\n",
    "\n",
    "# Load the corresponding image URLs from the local JSON file.\n",
    "image_URLs = read_json(\"RAW_DATASET/image_urls.json\")\n",
    "\n",
    "# Determine the total number of images to be processed (based on the number of URLs).\n",
    "n_images = len(image_URLs)\n",
    "\n",
    "# Set the device for computation: use GPU (\"cuda\") if available, otherwise fallback to CPU.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the pre-trained CLIP model (ViT-B/32) onto the selected device.\n",
    "# 'model' is the main neural network, and 'preprocess' is the required image transformation pipeline.\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(i):\n",
    "    \"\"\"\n",
    "    Loads an image file, applies necessary preprocessing (from CLIP), \n",
    "    and returns the resulting tensor along with its URL.\n",
    "    \"\"\"\n",
    "    # Construct the full path to the image using its ID.\n",
    "    image_path = f\".cache/Images/{image_IDs[i]}.jpg\"\n",
    "    \n",
    "    # Check if the file exists on the local filesystem.\n",
    "    if os.path.exists(image_path):\n",
    "        try:\n",
    "            # Open the image file using PIL.\n",
    "            image = Image.open(image_path)\n",
    "            \n",
    "            # Apply the standard CLIP preprocessing pipeline.\n",
    "            # 'preprocess' returns a PyTorch tensor (typically on CPU).\n",
    "            image_tensor = preprocess(image) \n",
    "            \n",
    "            # Return the original URL and the processed tensor.\n",
    "            return image_URLs[i], image_tensor\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Catch exceptions (e.g., File is corrupted, not a valid image format).\n",
    "            # Print an error message and skip the problematic image.\n",
    "            print(f\"Error processing image {image_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Return None if the image file was not found at the specified path.\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_HDF5_files(input_list, output_file):\n",
    "    \"\"\"\n",
    "    Merges data (URLs and embeddings) from multiple HDF5 files into a single output file.\n",
    "    \"\"\"\n",
    "    if not input_list:\n",
    "        print(\"❌ Error: Input file list is empty.\")\n",
    "        return\n",
    "\n",
    "    total_records = 0\n",
    "\n",
    "    # 1. Initialize Output Structure based on the first valid file\n",
    "    first_file = None\n",
    "    # Find the first existing file to determine the required structure (dtype, shape).\n",
    "    for f_path in input_list:\n",
    "        if os.path.exists(f_path):\n",
    "            first_file = f_path\n",
    "            break\n",
    "\n",
    "    if not first_file:\n",
    "        print(\"❌ Error: No valid input files found.\")\n",
    "        return\n",
    "\n",
    "    with h5py.File(first_file, 'r') as f_first:\n",
    "        # Get embedding dimension (shape[1]) and data types (dtype) for initialization.\n",
    "        # np.squeeze is used to handle potential extra dimensions (e.g., shape (N, 1, D) -> (N, D)).\n",
    "        embed_shape = np.squeeze(f_first['embeddings'][:]).shape[1]\n",
    "        embed_dtype = f_first['embeddings'].dtype\n",
    "        url_dtype = f_first['urls'].dtype\n",
    "\n",
    "    # Create the output file and initialize extendable datasets.\n",
    "    with h5py.File(output_file, 'w') as f_output:\n",
    "        # Initialize 'urls' dataset with zero length, maxshape=(None,) allows extension.\n",
    "        f_output.create_dataset(\n",
    "            'urls',\n",
    "            shape=(0,),\n",
    "            maxshape=(None,),\n",
    "            dtype=url_dtype,\n",
    "            chunks=True\n",
    "        )\n",
    "        # Initialize 'embeddings' dataset with zero length, maxshape=(None, embed_shape) allows extension.\n",
    "        f_output.create_dataset(\n",
    "            'embeddings',\n",
    "            shape=(0, embed_shape),\n",
    "            maxshape=(None, embed_shape),\n",
    "            dtype=embed_dtype,\n",
    "            chunks=True\n",
    "        )\n",
    "\n",
    "    pbar = tqdm(total = len(input_list), desc=\"Merging\")\n",
    "\n",
    "    # 2. Loop through input files and append data\n",
    "    # Open the output file in append mode ('a') for modification.\n",
    "    with h5py.File(output_file, 'a') as f_output:\n",
    "        for file_path in input_list:\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"⚠️ File not found: {file_path}. Skipping.\")\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                with h5py.File(file_path, 'r') as f_input:\n",
    "                    # Read data from the current input file.\n",
    "                    current_urls = f_input['urls'][:]\n",
    "                    current_embeddings = f_input['embeddings'][:]\n",
    "                    current_embeddings = np.squeeze(current_embeddings)\n",
    "                    num_records = current_urls.shape[0]\n",
    "\n",
    "                    if num_records == 0:\n",
    "                        continue\n",
    "\n",
    "                    dset_urls = f_output['urls']\n",
    "                    dset_embeddings = f_output['embeddings']\n",
    "\n",
    "                    new_size = total_records + num_records\n",
    "\n",
    "                    # Resize the datasets in the output file to accommodate new records.\n",
    "                    dset_urls.resize(new_size, axis=0)\n",
    "                    dset_embeddings.resize(new_size, axis=0)\n",
    "\n",
    "                    # Write the current file's data into the newly reserved space.\n",
    "                    dset_urls[total_records:new_size] = current_urls\n",
    "                    dset_embeddings[total_records:new_size] = current_embeddings\n",
    "\n",
    "                    # Update the running total of merged records.\n",
    "                    total_records = new_size\n",
    "\n",
    "            except Exception as e:\n",
    "                # Handle potential errors during file reading or resizing.\n",
    "                print(f\"❌ Error processing file {file_path}: {e}. Skipping this file.\")\n",
    "\n",
    "            pbar.update(1)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Main Processing Pipeline (Loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the main logic is executed. The pipeline runs in **chunks** to save memory and be fault-tolerant.\n",
    "* For **each chunk**, the script will:\n",
    "    1.  **Download Images:** Call the `downloader.py` script to download the images for the current chunk.\n",
    "    2.  **Preprocess (CPU):** Use a `ThreadPoolExecutor` to run the `load_and_preprocess_image` function in parallel.\n",
    "    3.  **Encode (GPU):** Gather preprocessed images into large batches, push them to the GPU, and run `model.encode_image` to get the vectors.\n",
    "    4.  **Save Chunk:** Write the URLs and vectors for this chunk into a temporary HDF5 file (e.g., `OUTPUT/Images_Embedded_0.h5`).\n",
    "    5.  **Cleanup Chunk:** Delete the temporary image directory (`.cache/Images`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = 0\n",
    "END = n_images\n",
    "CHUNK = 10000\n",
    "GPU_BATCH_SIZE = 512 \n",
    "NUM_WORKERS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T11:46:39.544925Z",
     "iopub.status.busy": "2025-11-02T11:46:39.544412Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c78512f68d439aa3f12ed0fded1051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images: 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Ensure the main output directory for embedded HDF5 files exists.\n",
    "os.makedirs(\"OUTPUT\", exist_ok=True) \n",
    "\n",
    "# Initialize a progress bar for monitoring the total images to be embedded.\n",
    "pbar = tqdm(total = END - START, desc = \"Embedding: \")\n",
    "\n",
    "# Main loop: Iterate over the image indices in defined CHUNK sizes.\n",
    "for x in range(START, END, CHUNK):\n",
    "\n",
    "    # 1. DOWNLOAD IMAGES FOR CURRENT CHUNK    \n",
    "    # Generate a temporary list file containing image IDs for the current chunk.\n",
    "    with open(\".cache/list_images.txt\", 'w', encoding='utf-8') as file:\n",
    "        for i in range(x, min(n_images, x + CHUNK)):\n",
    "            # Format: 'train/<image_id>'\n",
    "            file.write(\"train/\" + image_IDs[i] + \"\\n\")\n",
    "\n",
    "    # Ensure the target image download directory exists.\n",
    "    os.makedirs(\".cache/Images\", exist_ok=True)\n",
    "    \n",
    "    # Execute the external Python downloader script.\n",
    "    # It reads the list_images.txt and downloads files into .cache/Images using 100 processes.\n",
    "    subprocess.run([\n",
    "        \"python\", \".cache/downloader.py\", \".cache/list_images.txt\",\n",
    "        \"--download_folder=.cache/Images\", \"--num_processes=100\"\n",
    "    ])\n",
    "\n",
    "    # 2. READ & PREPROCESS IMAGES (CPU - Multi-threading)\n",
    "    # List to store (URL, preprocessed_tensor_on_CPU) tuples.\n",
    "    preprocessed_data_cpu = [] \n",
    "    \n",
    "    # Use ThreadPoolExecutor to parallelize I/O and image loading/preprocessing.\n",
    "    with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "        # Submit the load_and_preprocess_image function for each image index in the chunk.\n",
    "        futures = [executor.submit(load_and_preprocess_image, i) for i in range(x, min(n_images, x + CHUNK))]\n",
    "        \n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                # Append only successful results (not None).\n",
    "                preprocessed_data_cpu.append(result)\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Skip the current chunk if no images were successfully processed (e.g., all failed/corrupted).\n",
    "    if not preprocessed_data_cpu:\n",
    "        print(f\"No images were processed in chunk {int(x / CHUNK)}\")\n",
    "        # Clean up the downloaded images before continuing.\n",
    "        subprocess.run([\"rm\", \"-rf\", \".cache/Images\"])\n",
    "        continue\n",
    "\n",
    "    # 3. EMBEDDING CALCULATION (GPU - Batch Processing)\n",
    "    final_urls = []\n",
    "    final_embeddings_list = []\n",
    "\n",
    "    # Separate URLs and Tensors for batch processing.\n",
    "    urls_cpu = [item[0] for item in preprocessed_data_cpu]\n",
    "    tensors_cpu = [item[1] for item in preprocessed_data_cpu]\n",
    "\n",
    "    # Disable gradient computation - CRITICAL for memory efficiency during inference.\n",
    "    with torch.no_grad():\n",
    "        # Iterate over the preprocessed tensors in GPU_BATCH_SIZE chunks.\n",
    "        for i in range(0, len(tensors_cpu), GPU_BATCH_SIZE):\n",
    "            batch_tensors_cpu = tensors_cpu[i : i + GPU_BATCH_SIZE]\n",
    "            batch_urls = urls_cpu[i : i + GPU_BATCH_SIZE]\n",
    "            \n",
    "            # Stack individual tensors into a single batch tensor on the CPU.\n",
    "            batch_on_cpu = torch.stack(batch_tensors_cpu)\n",
    "            # Move the entire batch to the designated device (GPU).\n",
    "            batch_on_gpu = batch_on_cpu.to(device)\n",
    "\n",
    "            # Generate image embeddings using the CLIP model.\n",
    "            vectors_gpu = model.encode_image(batch_on_gpu)\n",
    "            \n",
    "            # Normalize the vectors (L2 normalization), required for standard CLIP usage.\n",
    "            vectors_gpu = vectors_gpu / vectors_gpu.norm(dim=-1, keepdim=True)\n",
    "            \n",
    "            # Convert GPU tensor to numpy array (CPU) for HDF5 writing.\n",
    "            vectors_numpy = vectors_gpu.cpu().detach().numpy().astype(np.float32)\n",
    "\n",
    "            # Store results for final HDF5 file.\n",
    "            final_urls.extend(batch_urls)\n",
    "            final_embeddings_list.append(vectors_numpy)\n",
    "\n",
    "    # 4. WRITE HDF5 FILE\n",
    "    # Construct the output path for the current chunk's embedding file.\n",
    "    output_path = f\"OUTPUT/Images_Embedded_{int(x / CHUNK)}.h5\"\n",
    "    \n",
    "    # Only write if the file doesn't exist and we have data to write.\n",
    "    if not os.path.exists(output_path) and final_embeddings_list:\n",
    "        # Combine all batch numpy arrays into a single large array.\n",
    "        all_embeddings_numpy = np.vstack(final_embeddings_list)\n",
    "        \n",
    "        # Write the URLs and embeddings into a new HDF5 file.\n",
    "        with h5py.File(output_path, \"w\") as outfile:\n",
    "            # URLs are stored as byte strings (dtype='S') in HDF5.\n",
    "            outfile.create_dataset(\"urls\", data=np.array(final_urls, dtype='S'))\n",
    "            outfile.create_dataset(\"embeddings\", data=all_embeddings_numpy)\n",
    "\n",
    "    # 5. CLEANUP\n",
    "    # Delete the downloaded images for the current chunk to save disk space.\n",
    "    subprocess.run([\"rm\", \"-rf\", \".cache/Images\"])\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge:** Call `merge_HDF5_files` to combine all temporary HDF5 chunk files into a single final file: `OUTPUT/Images_Embedded.h5`.\n",
    "**Final Cleanup:** Delete all the temporary HDF5 chunk files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4237b7a5e2144981a3feb3de254096e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Merging:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. MERGE CHUNKED HDF5 FILES\n",
    "# Generate a list of all HDF5 chunk files created during the embedding process.\n",
    "file_chunks = [\n",
    "    f\"OUTPUT/Images_Embedded_{int(x / CHUNK)}.h5\"\n",
    "    for x in range(START, END, CHUNK)\n",
    "]\n",
    "\n",
    "# Define the final, consolidated HDF5 file path.\n",
    "file_gop_cuoi = f\"OUTPUT/Images_Embedded.h5\"\n",
    "\n",
    "# Call the function to merge all chunk files into the single final file.\n",
    "merge_HDF5_files(file_chunks, file_gop_cuoi)\n",
    "\n",
    "# 2. CLEANUP: REMOVE TEMPORARY CHUNKS\n",
    "# Iterate through the indices used to generate the chunk files.\n",
    "for x in range(START, END, CHUNK):\n",
    "    chunk_path = f\"OUTPUT/Images_Embedded_{int(x / CHUNK)}.h5\"\n",
    "    try:\n",
    "        # Delete the individual temporary HDF5 chunk file to free up disk space.\n",
    "        os.remove(chunk_path)\n",
    "    except FileNotFoundError:\n",
    "        # Handle case where the file might have been skipped or already deleted.\n",
    "        print(f\"⚠️ Warning: Chunk file not found during cleanup: {chunk_path}\")\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8629323,
     "sourceId": 13582735,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "WEB-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
