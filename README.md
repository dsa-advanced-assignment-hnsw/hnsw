# HNSW Image Search Engine

A powerful image search engine that uses natural language queries to find similar images. Built with CLIP embeddings and HNSW (Hierarchical Navigable Small World) algorithm for fast and accurate similarity search.

## ğŸŒŸ Features

- ğŸ” **Natural Language Search**: Search images using descriptive text queries
- ğŸ–¼ï¸ **Image-to-Image Search**: Upload an image to find visually similar images
- âš¡ **Fast Similarity Search**: HNSW algorithm for efficient nearest neighbor search
- ğŸ¨ **Modern UI**: Beautiful, responsive interface built with Next.js and Tailwind CSS
- ğŸ¤– **CLIP Embeddings**: State-of-the-art vision-language model by OpenAI
- ğŸ“Š **Similarity Scores**: Visual feedback showing match confidence
- ğŸŒ“ **Dark Mode**: Full dark mode support
- ğŸ“± **Dual Search Modes**: Toggle between text and image search seamlessly

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Frontend (Next.js)              â”‚
â”‚  â€¢ React with TypeScript                         â”‚
â”‚  â€¢ Tailwind CSS for styling                      â”‚
â”‚  â€¢ Deployed on Vercel                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Backend (Flask)                     â”‚
â”‚  â€¢ CLIP model for text & image encoding          â”‚
â”‚  â€¢ HNSW index for similarity search              â”‚
â”‚  â€¢ HDF5 storage for embeddings                   â”‚
â”‚  â€¢ Image upload & processing                     â”‚
â”‚  â€¢ Deployed on Railway/Render                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- **Backend**: Python 3.8+, pip
- **Frontend**: Node.js 18+ or Bun
- **Data**: Pre-computed `images_embeds.h5` file

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/dsa-advanced-assignment-hnsw.git
cd dsa-advanced-assignment-hnsw
```

### 2. Setup Backend

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run server
python server.py
```

Backend will be available at `http://localhost:5000`

### 3. Setup Frontend

```bash
cd client

# Install dependencies
yarn install  # or npm install

# Create environment file
echo "NEXT_PUBLIC_API_URL=http://localhost:5000" > .env.local

# Run development server
yarn dev  # or npm run dev
```

Frontend will be available at `http://localhost:3000`

### 4. Open in Browser

Visit [http://localhost:3000](http://localhost:3000) and start searching!

## ğŸ“š Documentation

- **[Backend README](backend/README.md)** - API documentation and backend setup
- **[Frontend README](client/README.md)** - UI customization and frontend development
- **[Deployment Guide](DEPLOYMENT.md)** - Complete deployment instructions for production

## ğŸ¯ How It Works

1. **Image Preprocessing**: Images are converted to embeddings using CLIP ViT-B/32 model
2. **HNSW Index**: Embeddings are indexed using HNSW for efficient similarity search
3. **Text Query**: User's text query is converted to embedding using the same CLIP model
4. **Similarity Search**: HNSW finds k-nearest neighbors based on cosine similarity
5. **Results**: Top matching images are returned with similarity scores

## ğŸ› ï¸ Technology Stack

### Backend
- **Framework**: Flask 3.0
- **ML Model**: OpenAI CLIP (ViT-B/32)
- **Vector Search**: hnswlib
- **Data Storage**: HDF5 (h5py)
- **Deep Learning**: PyTorch

### Frontend
- **Framework**: Next.js 15
- **Language**: TypeScript
- **Styling**: Tailwind CSS
- **Deployment**: Vercel

## ğŸ“Š API Endpoints

### Search Images by Text
```bash
POST /search
Content-Type: application/json

{
  "query": "beach sunset",
  "k": 20
}
```

### Search Images by Image
```bash
POST /search/image
Content-Type: multipart/form-data

FormData:
- image: [image file]
- k: 20
```

### Get Image
```bash
GET /image/:path
```

### Health Check
```bash
GET /health
```

## ğŸš¢ Deployment

### Quick Deploy

1. **Backend to Railway:**
   ```bash
   # Connect repo to Railway and deploy
   ```

2. **Frontend to Vercel:**
   ```bash
   cd client
   vercel
   ```

See [DEPLOYMENT.md](DEPLOYMENT.md) for detailed instructions.

## ğŸ“ Project Structure

```
dsa-advanced-assignment-hnsw/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ server.py              # Flask API server
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â”œâ”€â”€ images_embeds.h5      # Pre-computed embeddings
â”‚   â”œâ”€â”€ search_using_hnsw.ipynb # Research notebook
â”‚   â””â”€â”€ README.md              # Backend documentation
â”œâ”€â”€ client/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ app/
â”‚   â”‚       â””â”€â”€ page.tsx       # Main search interface
â”‚   â”œâ”€â”€ package.json           # Node dependencies
â”‚   â”œâ”€â”€ vercel.json           # Vercel configuration
â”‚   â””â”€â”€ README.md              # Frontend documentation
â”œâ”€â”€ DEPLOYMENT.md              # Deployment guide
â””â”€â”€ README.md                  # This file
```

## ğŸ§ª Example Queries

Try these search queries:
- "dog playing in park"
- "beach sunset"
- "mountain landscape"
- "city skyline at night"
- "cat sleeping"

## ğŸ”§ Configuration

### Backend Configuration

Edit `backend/server.py`:
```python
# Change port
app.run(host='0.0.0.0', port=5000)

# Configure CORS
CORS(app, origins=["https://your-domain.com"])
```

### Frontend Configuration

Edit `client/.env.local`:
```env
NEXT_PUBLIC_API_URL=https://your-backend-url.com
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ™ Acknowledgments

- [OpenAI CLIP](https://github.com/openai/CLIP) for the vision-language model
- [hnswlib](https://github.com/nmslib/hnswlib) for fast approximate nearest neighbor search
- [Next.js](https://nextjs.org/) for the frontend framework
- [Flask](https://flask.palletsprojects.com/) for the backend framework

## ğŸ“ Support

- ğŸ“§ Email: your-email@example.com
- ğŸ’¬ Issues: [GitHub Issues](https://github.com/yourusername/dsa-advanced-assignment-hnsw/issues)

## â­ Star History

If you find this project useful, please consider giving it a star!

---

**Built with â¤ï¸ using CLIP, HNSW, Flask, and Next.js** 