{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (4.57.1)\n",
            "Requirement already satisfied: huggingface-hub in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (0.36.0)\n",
            "Requirement already satisfied: cloudinary in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (1.44.1)\n",
            "Requirement already satisfied: pillow in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (12.0.0)\n",
            "Requirement already satisfied: requests in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (2.32.5)\n",
            "Requirement already satisfied: h5py in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (3.15.1)\n",
            "Requirement already satisfied: tqdm in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (4.67.1)\n",
            "Requirement already satisfied: numpy in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (2.3.5)\n",
            "Requirement already satisfied: torch in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (2.9.0)\n",
            "Requirement already satisfied: open-clip-torch in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from huggingface-hub) (2025.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from huggingface-hub) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from huggingface-hub) (1.2.0)\n",
            "Requirement already satisfied: six in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from cloudinary) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from cloudinary) (2.5.0)\n",
            "Requirement already satisfied: certifi in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from cloudinary) (2025.10.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from requests) (3.11)\n",
            "Requirement already satisfied: setuptools in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: torchvision in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from open-clip-torch) (0.24.0)\n",
            "Requirement already satisfied: ftfy in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from open-clip-torch) (6.3.1)\n",
            "Requirement already satisfied: timm>=1.0.17 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from open-clip-torch) (1.0.22)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: wcwidth in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from ftfy->open-clip-torch) (0.2.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/huynguyen/miniconda3/envs/WEB-dev/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers huggingface-hub cloudinary pillow requests h5py tqdm numpy torch open-clip-torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from io import BytesIO\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import hnswlib\n",
        "import requests\n",
        "import time\n",
        "import h5py\n",
        "from PIL import Image, ImageFile  # Import th√™m ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True  # Cho ph√©p ƒë·ªçc ·∫£nh b·ªã l·ªói nh·∫π\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check dependencies\n",
        "try:\n",
        "    import torch\n",
        "    import open_clip\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Missing dependency: {e}\")\n",
        "    print(\"\\nPlease install required packages:\")\n",
        "    print(\"  conda activate hnsw-backend-venv\")\n",
        "    print(\"  pip install open-clip-torch\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Check dependencies\n",
        "try:\n",
        "    import cloudinary\n",
        "    import cloudinary.api\n",
        "    import cloudinary.uploader\n",
        "    from transformers import AutoModel, AutoProcessor\n",
        "    import torch\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Missing dependency: {e}\")\n",
        "    print(\"\\nPlease install required packages:\")\n",
        "    print(\"  pip install transformers huggingface-hub cloudinary pillow requests h5py tqdm numpy torch\")\n",
        "    sys.exit(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_biomedclip():\n",
        "    \"\"\"Load BiomedCLIP model using open_clip\"\"\"\n",
        "    print(\"\\nü§ñ Loading BiomedCLIP model...\")\n",
        "    print(\"   Model: hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224\")\n",
        "    print(\"   This may take a few minutes on first run (downloads ~2GB)\\n\")\n",
        "    \n",
        "    # Load BiomedCLIP using open_clip\n",
        "    model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms(\n",
        "        'hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224'\n",
        "    )\n",
        "    tokenizer = open_clip.get_tokenizer('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
        "    \n",
        "    # Move to GPU if available\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model.to(device)\n",
        "    model.eval()  # Set to evaluation mode\n",
        "    \n",
        "    print(f\"‚úÖ Model loaded successfully!\")\n",
        "    print(f\"   Device: {device}\")\n",
        "    print(f\"   Embedding dimension: 512\")\n",
        "    \n",
        "    # Test the model\n",
        "    test_text = \"femur fracture\"\n",
        "    text_tokens = tokenizer([test_text]).to(device)\n",
        "    with torch.no_grad():\n",
        "        text_features = model.encode_text(text_tokens)\n",
        "        text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "    \n",
        "    print(f\"\\nüß™ Test encoding: '{test_text}'\")\n",
        "    print(f\"   Output shape: {text_features.shape}\")\n",
        "    print(f\"   ‚úÖ Model is working correctly!\")\n",
        "    \n",
        "    return model, preprocess_val, tokenizer, device\n",
        "\n",
        "def encode_image(image_path, model, preprocess, device):\n",
        "    \"\"\"Encode a single image to embedding\"\"\"\n",
        "    try:\n",
        "        # Open and convert to RGB\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        \n",
        "        # Preprocess image\n",
        "        image_tensor = preprocess(image).unsqueeze(0).to(device)\n",
        "        \n",
        "        # Generate embedding\n",
        "        with torch.no_grad():\n",
        "            image_features = model.encode_image(image_tensor)\n",
        "            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "        \n",
        "        return image_features.cpu().numpy().astype(np.float32)[0]\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Failed to process {image_path}: {e}\")\n",
        "        return None\n",
        "    \n",
        "def get_text_embedding(text_input, model, tokenizer, device):\n",
        "    \"\"\"\n",
        "    Chuy·ªÉn ƒë·ªïi text (ho·∫∑c list c√°c text) th√†nh vector embedding ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a.\n",
        "    \n",
        "    Args:\n",
        "        text_input: M·ªôt chu·ªói (str) ho·∫∑c m·ªôt danh s√°ch chu·ªói (list of str).\n",
        "        model: Model BiomedCLIP ƒë√£ load.\n",
        "        tokenizer: Tokenizer c·ªßa BiomedCLIP.\n",
        "        device: 'cuda' ho·∫∑c 'cpu'.\n",
        "        \n",
        "    Returns:\n",
        "        numpy.ndarray: M·∫£ng vector embedding (shape: [n, 512]).\n",
        "    \"\"\"\n",
        "    \n",
        "    # 1. X·ª≠ l√Ω ƒë·∫ßu v√†o: ƒê·∫£m b·∫£o lu√¥n l√† list ƒë·ªÉ tokenizer ho·∫°t ƒë·ªông ƒë√∫ng\n",
        "    if isinstance(text_input, str):\n",
        "        text_input = [text_input]\n",
        "        \n",
        "    # 2. Tokenize: Chuy·ªÉn text th√†nh token ID\n",
        "    # context_length c·ªßa BiomedCLIP n√†y l√† 256\n",
        "    tokens = tokenizer(text_input).to(device)\n",
        "    \n",
        "    # 3. Inference: Ch·∫°y model ƒë·ªÉ l·∫•y feature\n",
        "    with torch.no_grad():\n",
        "        text_features = model.encode_text(tokens)\n",
        "        \n",
        "        # 4. Normalization (QUAN TR·ªåNG): \n",
        "        # C·∫ßn chia cho ƒë·ªô d√†i vector (L2 norm) ƒë·ªÉ ƒë∆∞a v·ªÅ ƒë∆°n v·ªã chu·∫©n.\n",
        "        # N·∫øu kh√¥ng l√†m b∆∞·ªõc n√†y, t√≠nh Cosine Similarity s·∫Ω b·ªã sai.\n",
        "        text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "        \n",
        "    # 5. Chuy·ªÉn v·ªÅ Numpy array ƒë·ªÉ d·ªÖ l∆∞u v√†o HNSW/Database\n",
        "    return text_features.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ü§ñ Loading BiomedCLIP model...\n",
            "   Model: hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224\n",
            "   This may take a few minutes on first run (downloads ~2GB)\n",
            "\n",
            "‚úÖ Model loaded successfully!\n",
            "   Device: cuda\n",
            "   Embedding dimension: 512\n",
            "\n",
            "üß™ Test encoding: 'femur fracture'\n",
            "   Output shape: torch.Size([1, 512])\n",
            "   ‚úÖ Model is working correctly!\n"
          ]
        }
      ],
      "source": [
        "model, processor, tokenizer, device = load_biomedclip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = json.load(open('cloudinary_urls.json'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3366\n"
          ]
        }
      ],
      "source": [
        "print(len(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3366/3366 [01:00<00:00, 55.85it/s]\n"
          ]
        }
      ],
      "source": [
        "urls = []\n",
        "all_embeddings_numpy = []\n",
        "\n",
        "for i in tqdm(range(len(dataset))):\n",
        "    url = dataset[i]['url']\n",
        "    image_path = dataset[i]['local_path']\n",
        "    embeddings = encode_image(image_path, model, processor, device)\n",
        "    if embeddings is not None:\n",
        "        urls.append(url)\n",
        "        all_embeddings_numpy.append(embeddings)\n",
        "\n",
        "all_embeddings = np.array(all_embeddings_numpy)\n",
        "norms = np.linalg.norm(all_embeddings_numpy, axis=1, keepdims=True)\n",
        "all_embeddings_numpy = all_embeddings_numpy / norms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_path = \"../backend/temp/Medical_Embedded.h5\"\n",
        "\n",
        "with h5py.File(output_path, \"w\") as outfile:\n",
        "    outfile.create_dataset(\"urls\", data=np.array(urls, dtype='S')) \n",
        "    outfile.create_dataset(\"embeddings\", data=all_embeddings_numpy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_bin_path = \"../backend/temp/Medical_Embedded.bin\"\n",
        "\n",
        "data = h5py.File(output_path, \"r\")\n",
        "p = hnswlib.Index(space='cosine', dim=512)\n",
        "p.init_index(max_elements=10000, ef_construction=400, M=200)\n",
        "p.add_items(data[\"embeddings\"])\n",
        "p.set_ef(400)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "p.save_index(output_bin_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(array([[1147, 3107,   54, 1993, 1793, 1741,  885, 2999, 3269,  616]],\n",
            "      dtype=uint64), array([[0.5979632 , 0.60067916, 0.6017135 , 0.6060069 , 0.6070913 ,\n",
            "        0.60986036, 0.61100316, 0.6114818 , 0.61228967, 0.61520696]],\n",
            "      dtype=float32))\n"
          ]
        }
      ],
      "source": [
        "xyz = p.knn_query(get_text_embedding(\"arm\", model, tokenizer, device), 10)\n",
        "print(xyz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://res.cloudinary.com/dp4qen6gz/image/upload/v1765208122/medical/fractures_2/IMG0002064.jpg\n"
          ]
        }
      ],
      "source": [
        "print(dataset[2999][\"url\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "WEB-dev",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
